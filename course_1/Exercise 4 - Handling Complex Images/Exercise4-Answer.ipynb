{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Exercises/Exercise%204%20-%20Handling%20Complex%20Images/Exercise4-Answer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zX4Kg8DUTKWO"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yuxiangzhang/Documents/GitHub/dlaicourse/Exercises/Exercise 4 - Handling Complex Images'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NFuMFYXtwsT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-15 21:22:15--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\n",
      "Resolving storage.googleapis.com... 2607:f8b0:400a:804::2010, 216.58.193.80\n",
      "Connecting to storage.googleapis.com|2607:f8b0:400a:804::2010|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2670333 (2.5M) [application/zip]\n",
      "Saving to: '/tmp/happy-or-sad.zip'\n",
      "\n",
      "/tmp/happy-or-sad.z 100%[===================>]   2.55M  7.20MB/s    in 0.4s    \n",
      "\n",
      "2020-06-15 21:22:16 (7.20 MB/s) - '/tmp/happy-or-sad.zip' saved [2670333/2670333]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "DESIRED_ACCURACY = 0.999\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "    \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\" \\\n",
    "    -O \"/tmp/happy-or-sad.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_ref = zipfile.ZipFile(\"/tmp/happy-or-sad.zip\", 'r')\n",
    "zip_ref.extractall(\"/tmp/h-or-s\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_happy_sad_model\n",
    "def train_happy_sad_model():\n",
    "    # Please write your code only where you are indicated.\n",
    "    # please do not remove # model fitting inline comments.\n",
    "\n",
    "    DESIRED_ACCURACY = 0.999\n",
    "\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('acc')>DESIRED_ACCURACY):\n",
    "                print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "    callbacks = myCallback()\n",
    "    \n",
    "    # This Code Block should Define and Compile the Model. Please assume the images are 150 X 150 in your implementation.\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "            tf.keras.layers.MaxPooling2D(2, 2),\n",
    "            tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(512, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.001), metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "    # This code block should create an instance of an ImageDataGenerator called train_datagen \n",
    "    # And a train_generator by calling train_datagen.flow_from_directory\n",
    "\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "    # Please use a target_size of 150 X 150.\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        # Your Code Here\n",
    "        '/tmp/h-or-s',\n",
    "        target_size = (150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    # Expected output: 'Found 80 images belonging to 2 classes'\n",
    "\n",
    "    # This code block should call model.fit_generator and train for\n",
    "    # a number of epochs.\n",
    "    # model fitting\n",
    "    history = model.fit_generator(\n",
    "          # Your Code Here\n",
    "        train_generator,\n",
    "        steps_per_epoch=4,\n",
    "        epochs=15,\n",
    "        verbose=2,\n",
    "        callbacks=[callbacks]\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_happy_sad_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_happy_sad_model\n",
    "def train_happy_sad_model():\n",
    "    # Please write your code only where you are indicated.\n",
    "    # please do not remove # model fitting inline comments.\n",
    "\n",
    "    DESIRED_ACCURACY = 0.999\n",
    "\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('acc')>DESIRED_ACCURACY):\n",
    "                print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "    callbacks = myCallback()\n",
    "    \n",
    "    # This Code Block should Define and Compile the Model. Please assume the images are 150 X 150 in your implementation.\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "            tf.keras.layers.MaxPooling2D(2, 2),\n",
    "            tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(512, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.001), metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "    # This code block should create an instance of an ImageDataGenerator called train_datagen \n",
    "    # And a train_generator by calling train_datagen.flow_from_directory\n",
    "\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "    # Please use a target_size of 150 X 150.\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        # Your Code Here\n",
    "        '/tmp/h-or-s',\n",
    "        target_size = (150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    \n",
    "    # Expected output: 'Found 80 images belonging to 2 classes'\n",
    "\n",
    "    # This code block should call model.fit_generator and train for\n",
    "    # a number of epochs.\n",
    "    # model fitting\n",
    "    history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=4,\n",
    "        epochs=15,\n",
    "        verbose=2,\n",
    "        callbacks=[callbacks]\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      " - 4s - loss: 1.6887 - acc: 0.4875\n",
      "Epoch 2/15\n",
      " - 2s - loss: 0.5217 - acc: 0.7375\n",
      "Epoch 3/15\n",
      " - 2s - loss: 0.5239 - acc: 0.7875\n",
      "Epoch 4/15\n",
      " - 1s - loss: 0.2762 - acc: 0.8750\n",
      "Epoch 5/15\n",
      " - 1s - loss: 0.1636 - acc: 0.9250\n",
      "Epoch 6/15\n",
      " - 1s - loss: 0.3468 - acc: 0.8500\n",
      "Epoch 7/15\n",
      " - 2s - loss: 0.2862 - acc: 0.9375\n",
      "Epoch 8/15\n",
      " - 2s - loss: 0.0721 - acc: 0.9625\n",
      "Epoch 9/15\n",
      " - 2s - loss: 0.1101 - acc: 0.9625\n",
      "Epoch 10/15\n",
      " - 1s - loss: 0.0584 - acc: 0.9750\n",
      "Epoch 11/15\n",
      " - 1s - loss: 0.1349 - acc: 0.9500\n",
      "Epoch 12/15\n",
      " - 1s - loss: 0.1055 - acc: 0.9750\n",
      "Epoch 13/15\n",
      " - 2s - loss: 0.0493 - acc: 0.9875\n",
      "Epoch 14/15\n",
      "\n",
      "Reached 99.9% accuracy so cancelling training!\n",
      " - 1s - loss: 0.0231 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_happy_sad_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "            tf.keras.layers.MaxPooling2D(2, 2),\n",
    "            tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(512, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_69 (Conv2D)           (None, 148, 148, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 72, 72, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 34, 34, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 9248)              0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 512)               4735488   \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 4,750,337\n",
      "Trainable params: 4,750,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnParaCnt(inputNode, node):\n",
    "    return inputNode * node + node\n",
    "\n",
    "def flattenCnt(inputDim=()):\n",
    "    prod = 1\n",
    "    for i in range(len(inputDim)):\n",
    "        prod *= inputDim[i]\n",
    "    return prod\n",
    "\n",
    "def conv3DCnt(f_width, f_length, prev_channel, numFilter):\n",
    "    return  f_width * f_length * prev_channel * numFilter + numFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv2d_69 (3, 3, 3, 16) (16,)\n",
      "Num of parameter: 448 = 3*3*3*16+16 \n",
      "\n",
      "1 max_pooling2d_69 \n",
      "\n",
      "2 conv2d_70 (3, 3, 16, 32) (32,)\n",
      "Num of parameter: 4640 = 3*3*16*32+32 \n",
      "\n",
      "3 max_pooling2d_70 \n",
      "\n",
      "4 conv2d_71 (3, 3, 32, 32) (32,)\n",
      "Num of parameter: 9248 = 3*3*32*32+32 \n",
      "\n",
      "5 max_pooling2d_71 \n",
      "\n",
      "6 flatten_23 \n",
      "\n",
      "7 dense_46 (9248, 512) (512,)\n",
      "Num of parameter: 4735488 = 9248*512+512 \n",
      "\n",
      "8 dense_47 (512, 1) (1,)\n",
      "Num of parameter: 513 = 512*1+1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    if len(layer.get_weights()) > 0:\n",
    "        filter_shape = layer.get_weights()[0].shape\n",
    "        name = layer.name.split('_')[0]\n",
    "        \n",
    "        if len(filter_shape) == 4:\n",
    "            print(i, layer.name, filter_shape, layer.get_weights()[1].shape)\n",
    "            print('Num of parameter: {} = {}*{}*{}*{}+{} \\n'\n",
    "                  .format(conv3DCnt(filter_shape[0],filter_shape[1],filter_shape[2],filter_shape[3]), \n",
    "                          filter_shape[0], filter_shape[1], filter_shape[2],filter_shape[3],filter_shape[3]))\n",
    "        \n",
    "        if len(filter_shape) == 2:   \n",
    "            print(i, layer.name, filter_shape, layer.get_weights()[1].shape)\n",
    "            print('Num of parameter: {} = {}*{}+{} \\n'.format(nnParaCnt(filter_shape[0], filter_shape[1]),\n",
    "                                                filter_shape[0], filter_shape[1], filter_shape[1]))\n",
    "        \n",
    "    else:\n",
    "        print(i, layer.name, '\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'dense_47',\n",
       " 'trainable': True,\n",
       " 'dtype': 'float32',\n",
       " 'units': 1,\n",
       " 'activation': 'sigmoid',\n",
       " 'use_bias': True,\n",
       " 'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "  'config': {'scale': 1.0,\n",
       "   'mode': 'fan_avg',\n",
       "   'distribution': 'uniform',\n",
       "   'seed': None,\n",
       "   'dtype': 'float32'}},\n",
       " 'bias_initializer': {'class_name': 'Zeros', 'config': {'dtype': 'float32'}},\n",
       " 'kernel_regularizer': None,\n",
       " 'bias_regularizer': None,\n",
       " 'activity_regularizer': None,\n",
       " 'kernel_constraint': None,\n",
       " 'bias_constraint': None}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_47/kernel:0' shape=(512, 1) dtype=float32>,\n",
       " <tf.Variable 'dense_47/bias:0' shape=(1,) dtype=float32>]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Exercise4-Answer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
